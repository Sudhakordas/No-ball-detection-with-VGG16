{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import image\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator ,array_to_img, img_to_array, load_img\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Original dataset/training'\n",
    "val_path = 'Original dataset/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator( rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = train_datagen.flow_from_directory(train_path,\n",
    "                                 target_size = (100,100),\n",
    "                                 #color_mode  = \"grayscale\",\n",
    "                                 batch_size=80,\n",
    "                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 833 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator( rescale = 1./255)\n",
    "valid_data = train_datagen.flow_from_directory(val_path,\n",
    "                                 target_size = (100,100),\n",
    "                                 #color_mode  = \"grayscale\",\n",
    "                                 batch_size=80,\n",
    "                                 class_mode = 'categorical')                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fair': 0, 'No ball': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3), activation = 'relu', input_shape = (100,100,3)),\n",
    "                                     tf.keras.layers.MaxPool2D(2,2),\n",
    "                                     tf.keras.layers.Dropout(.2),\n",
    "                                    \n",
    "                                    tf.keras.layers.Conv2D(32,(3,3), activation = 'relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    tf.keras.layers.Dropout(.3),\n",
    "                                    \n",
    "                                    \n",
    "                                    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    tf.keras.layers.Dropout(.2),\n",
    "                                    \n",
    "                                    \n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    \n",
    "                                    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "                                    \n",
    "                                    tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "                                    \n",
    "    \n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer ='adam',\n",
    "              metrics = ['accuracy'])  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 124s 4s/step - loss: 0.9162 - accuracy: 0.5882 - val_loss: 0.6847 - val_accuracy: 0.5618\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 63s 2s/step - loss: 0.6678 - accuracy: 0.5921 - val_loss: 0.6627 - val_accuracy: 0.5618\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 57s 2s/step - loss: 0.6125 - accuracy: 0.6252 - val_loss: 0.6126 - val_accuracy: 0.6519\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 57s 2s/step - loss: 0.5346 - accuracy: 0.7577 - val_loss: 0.4869 - val_accuracy: 0.7887\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 58s 2s/step - loss: 0.4526 - accuracy: 0.7815 - val_loss: 0.4743 - val_accuracy: 0.7731\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 66s 2s/step - loss: 0.4442 - accuracy: 0.7978 - val_loss: 0.3979 - val_accuracy: 0.8427\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 65s 2s/step - loss: 0.3417 - accuracy: 0.8477 - val_loss: 0.2825 - val_accuracy: 0.8860\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 64s 2s/step - loss: 0.2672 - accuracy: 0.8925 - val_loss: 0.2143 - val_accuracy: 0.9448\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 64s 2s/step - loss: 0.2069 - accuracy: 0.9170 - val_loss: 0.1533 - val_accuracy: 0.9508\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 64s 2s/step - loss: 0.1417 - accuracy: 0.9400 - val_loss: 0.1867 - val_accuracy: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x232bed4cac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data,  validation_data = valid_data,  epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('No_ball_predictor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def No_ball_prediction(img):\n",
    " # gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  test_image = image.load_img(img, target_size = (100, 100)) # load image \n",
    "  print(\"@@ Got Image for prediction\")\n",
    "   \n",
    "  test_image = image.img_to_array(test_image)/255 # convert image to np array and normalize\n",
    "  #plt.imshow(test_image)\n",
    "  test_image = np.expand_dims(test_image, axis = 0) # change dimention 3D to 4D\n",
    "   \n",
    "  result = model.predict(test_image).round(3) # predict class \n",
    "  print('@@ Raw result = ', result)\n",
    "   \n",
    "  pred = np.argmax(result) # get the index of max value\n",
    "  print(pred)\n",
    " \n",
    " \n",
    "  if pred == 0:\n",
    "    return \"Legal ball\" # if index 0 \n",
    "\n",
    "  else:\n",
    "    return \"No ball\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6e1222965452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'No ball/Front foot/70313012.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNo_ball_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-144ff5896ca7>\u001b[0m in \u001b[0;36mNo_ball_prediction\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mNo_ball_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mgray_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# load image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"@@ Got Image for prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "img_path = 'No ball/Front foot/70313012.jpg'\n",
    "No_ball_prediction(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
